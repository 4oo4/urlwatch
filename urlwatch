#!/usr/bin/python
#
# urlwatch is a minimalistic URL watcher written in Python
#
# Copyright (c) 2008 Thomas Perl <thp@thpinfo.com>
# All rights reserved.
# 
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
# 1. Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
# 3. The name of the author may not be used to endorse or promote products
#    derived from this software without specific prior written permission.
# 
# THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
# IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
# OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
# IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
# NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
# THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#

"""Watch web pages and arbitrary URLs for changes"""

pkgname = 'urlwatch'

__author__ = 'Thomas Perl <thp@thpinfo.com>'
__copyright__ = 'Copyright 2008 Thomas Perl'
__license__ = 'BSD'
__homepage__ = 'http://thpinfo.com/2008/urlwatch/'
__version__ = 1.5

user_agent = '%s/%s (+http://thpinfo.com/2008/urlwatch/info.html)' % (pkgname, __version__)

# Configuration section
display_errors = False
line_length = 75


# File and folder paths
import sys
import os.path

urlwatch_dir = os.path.expanduser(os.path.join('~', '.'+pkgname))
urls_txt = os.path.join(urlwatch_dir, 'urls.txt')
cache_dir = os.path.join(urlwatch_dir, 'cache')
scripts_dir = os.path.join(urlwatch_dir, 'lib')
hooks_py = os.path.join(scripts_dir, 'hooks.py')

# Check if we are installed in the system already
(prefix, bindir) = os.path.split(os.path.dirname(os.path.abspath(sys.argv[0])))

if bindir == 'bin':
    # Assume we are installed in system
    examples_dir = os.path.join(prefix, 'share', pkgname, 'examples')
else:
    # Assume we are not yet installed
    examples_dir = os.path.join(prefix, bindir, 'examples')
    sys.path.append(os.path.join(prefix, bindir, 'lib'))

urls_txt_example = os.path.join(examples_dir, 'urls.txt.example')
hooks_py_example = os.path.join(examples_dir, 'hooks.py.example')

# Code section
import sha
import shutil
import os
import urllib2
import difflib
import datetime

def foutput(type, url, content=None, summary=None, c='*', n=line_length):
    """Format output messages
    
    Returns a snippet of a specific message type (i.e. 'changed') for
    a specific URL and an optional (possibly multi-line) content.

    The parameter "summary" (if specified) should be a list variable
    that gets one item appended for the summary of the changes.

    The return value is a list of strings (one item per line).
    """
    summary_txt = ': '.join((type.upper(), url))

    if summary is not None:
        if content is None:
            summary.append(summary_txt)
        else:
            summary.append('%s (%d bytes)' % (summary_txt, len(content)))

    result = [c*n, summary_txt]
    if content is not None:
        result += [c*n, content]
    result += [c*n, '', '']

    return result


if __name__ == '__main__':
    start = datetime.datetime.now()

    # Created all needed folders
    for needed_dir in (urlwatch_dir, cache_dir, scripts_dir):
        if not os.path.isdir(needed_dir):
            os.makedirs(needed_dir)

    # Check for required files
    if not os.path.isfile(urls_txt):
        urls_txt_fn = os.path.join(os.path.dirname(urls_txt), os.path.basename(urls_txt_example))
        hooks_py_fn = os.path.join(os.path.dirname(hooks_py), os.path.basename(hooks_py_example))
        print 'Error: You need to create a urls.txt file first.'
        print ''
        print 'Place it in %s' % (urls_txt)
        print 'An example is available in %s' % (urls_txt_fn)
        print ''
        print 'You can also create %s' % (hooks_py)
        print 'An example is available in %s' % (hooks_py_fn)
        print ''
        if os.path.exists(urls_txt_example) and not os.path.exists(urls_txt_fn):
            shutil.copy(urls_txt_example, urls_txt_fn)
        if os.path.exists(hooks_py_example) and not os.path.exists(hooks_py_fn):
            shutil.copy(hooks_py_example, hooks_py_fn)
        sys.exit(1)

    headers = {
            'User-agent': user_agent,
    }

    summary = []
    details = []
    count = 0

    if os.path.exists(hooks_py):
        hooks = imp.load_source('hooks', hooks_py)
        if hasattr(hooks, 'filter'):
            filter = hooks.filter
        else:
            print 'WARNING: %s has no filter function - ignoring' % hooks_py
            filter = lambda x, y: y
    else:
        filter = lambda x, y: y

    for url in (x for x in open(urls_txt).read().splitlines() if not (x.startswith('#') or x.strip()=='')):
        filename = os.path.join(cache_dir, sha.new(url).hexdigest())
        try:
            request = urllib2.Request(url, None, headers)
            data = filter(url, urllib2.urlopen(request).read())
            if os.path.exists(filename):
                old_data = open(filename).read()
                diff = ''.join(difflib.unified_diff(old_data.splitlines(1), data.splitlines(1)))
                if len(diff) > 0:
                    details += foutput('changed', url, diff, summary)
            else:
                details += foutput('new', url, None, summary)
            open(filename, 'w').write(data)
        except urllib2.HTTPError, error:
            if display_errors:
                details += foutput('error', url, error, summary)
        except urllib2.URLError, error:
            if display_errors:
                details += foutput('error', url, error, summary)
        count += 1

    end = datetime.datetime.now()

    # Output everything
    if len(summary) > 1:
        print '-'*line_length
        print 'summary: %d changes' % (len(summary),)
        print ''
        for id, line in enumerate(summary):
            print '%02d. %s' % (id+1, line)
        print '-'*line_length
        print '\n\n\n'
    if len(details) > 1:
        print '\n'.join(details)
        print '-- '
        print '%s %s, %s' % (pkgname, __version__, __copyright__)
        print 'Website: %s' % (__homepage__,)
        print 'watched %d URLs in %d seconds\n' % (count, (end-start).seconds)

